---
title: "MATH70076: Data Science - Coursework 1"
subtitle: 'MSc in Statistics 2025/26, Imperial College London'
author: "02049284"
format:
  html:
    toc: true
    highlight: tango
    self-contained: true
  pdf: default
format-links: false
bibliography: example.bib 
---
```{r}
#| echo: false
library(ggplot2)
library(dplyr)

```
**Deadline:  Friday 10 October 2025 at 13:00.**

_For this assessment you should submit two files via the Imperial College VLE on Blackboard by the deadline stated above. Your files should be named as follows:_

- `YOURCID-MATH70076-assessment-1.pdf`: your rendered report,
- `YOURCID-MATH70076-assessment-1.zip`: a zip file containing the relevant source code to generate your report.

_All submitted materials should be clearly presented and be understandable as stand-alone documents._

_Please note that large files can take quite some time to upload. Ensure that you upload each document to the correct part of the learning space in a timely manner._

_This coursework is expected to take approximately 5 hours of individual effort and will be marked as Pass/Fail. Assessment criteria are given in the "set yourself up for success" boxes. Satisfying 15 or more out of these 20 criteria will constitute a pass grade._

_In submitting this assessment you certify that it is entirely your own work, apart from where otherwise acknowledged, and includes no plagiarism. Note that software tools are used as part of plagiarism detection._

-----

## Background 

### Generalised Pareto Distribution 

The Generalized Pareto Distribution (GPD) is a flexible family of continuous probability distributions that arises naturally in extreme value theory, particularly for modelling the distribution of excesses over a threshold. It is parametrised by a shape parameter $\xi \in \mathbb{R}$, a scale parameter $\sigma > 0$, and a location parameter $u \in \mathbb{R}$. Its cumulative distribution function (CDF) is given by

$$
F(x;\,\sigma,\xi, u) = 
\begin{cases}
1 - \left(1 + \dfrac{\xi (x-u)}{\sigma}\right)_+^{-1/\xi}, & \xi \neq 0, \, x \geq u; \; \\[1.2em]
1 - \exp\!\left(-\dfrac{x-u}{\sigma}\right), & \xi = 0, \, x \geq u;
\end{cases}
$$ {#eq-gpd-cdf}

where $x_+ = \max(x,0)$ and its probability density function (PDF) is

$$
f(x;\sigma,\xi,u) =
\begin{cases}
\dfrac{1}{\sigma}\left(1 + \dfrac{\xi (x-u)}{\sigma}\right)_+^{-1/\xi - 1}, & \xi \neq 0, \\[1.2em]
\dfrac{1}{\sigma}\exp\!\left(-\dfrac{x-u}{\sigma}\right), & \xi = 0,
\end{cases}
$$ {#eq-gpd-pdf}


defined on the same support as the CDF. The GPD encompasses a variety of tail behaviours:

- when $\xi > 0$ the GPD has heavy, slowly decaying tails, 
- in limiting case when $\xi \rightarrow 0$ the GPD reduces to an exponential distribution;
- when $\xi < 0$ the GPD has light, quickly decaying tails with a finite upper endpoint of $x^+ = u - \sigma / \xi$. 

### Probability Integral Transform

The probability integral transform states that if a random variable $X$ has a continuous cumulative distribution function $F_X(x)$, then the transformed variable $A = F_X(X)$ follows a uniform distribution on $[0,1]$. Conversely, if $F$ is an invertible function then $Y = F^{-1}_X(A)$ has the same distribution as $X$.

## Questions 

###  Question 1 

Derive an expression for the inverse cumulative distribution function (also known as the quantile function) $F^{-1}_X: [0,1] \rightarrow [u, x^+]$ of $X \sim \text{GPD}(u, \sigma, \xi)$. Your answer should refer to at least one equation given in the background material. 

::: {.callout-tip}
## Set yourself up for success

Does your answer contain:

- a few sentences of text describing your approach to the problem; 
- a reference to at least one equation from the background section;
- a correctly formatted LaTeX equation;
- a valid approach to the problem and correct expression.
:::


<!-- YOUR DERIVATION GOES HERE -->
 
To invert the cumulative distribution function of the GPD, to get $F^{-1}_X: [0,1] \rightarrow [u, x^+]$, we will start from @eq-gpd-cdf. There are 2 cases. Firstly when $\xi \neq 0$ but $\left(1 + \dfrac{\xi (x-u)}{\sigma}\right) > 0$. Solving for when this happens. As $x \geq u$, if $\xi >0$, this is always the case. But even when $\xi < 0$, we can get a positive value for  $\left(1 + \dfrac{\xi (x-u)}{\sigma}\right) > 0$. This happens if (keeping in mind that $\xi < 0 \implies -\xi > 0$): 

$$
\begin{aligned}
1 + \dfrac{\xi (x-u)}{\sigma} &> 0 \\
\implies \quad 1 &> -\dfrac{\xi (x-u)}{\sigma} \\
\implies \quad \dfrac{-\sigma}{\xi} &> x - u \\
\implies \quad u -\dfrac{\sigma}{\xi} &> x
\end{aligned}
$${#eq-cond-neg-xi}


This coincides with the range of the Inverse function mentioned. Hence we can safely proceed to the 2 cases.

**Case 1)** In  @eq-gpd-cdf, when $\left(1 + \dfrac{\xi (x-u)}{\sigma}\right) > 0$. As we can see from above, this happens when $\quad i) \xi >0$ or $\quad ii)$ from @eq-cond-neg-xi when $u -\dfrac{\sigma}{\xi} > x$.  Let $y = F(x;\,\sigma,\xi, u)$


$$
\begin{aligned}
 y &= 1 - \left(1 + \dfrac{\xi (x-u)}{\sigma}\right)^{-1/\xi}\\
 1-y &= \left(1 + \dfrac{\xi (x-u)}{\sigma}\right)^{-1/\xi}\\
 (1-y)^{-\xi} &= 1 + \dfrac{\xi (x-u)}{\sigma} \\
 - \dfrac{\xi (x-u)}{\sigma} &= 1 - (1-y)^{-\xi} \\
 x-u &= -\dfrac{\sigma}{\xi}(1 - (1-y)^{-\xi})\\
 x&= -\dfrac{\sigma}{\xi}(1 - (1-y)^{-\xi}) + u \\
 \implies F^{-1}_X(y) &= -\dfrac{\sigma}{\xi}(1 - (1-y)^{-\xi}) + u
 \end{aligned}
$${#eq-gpd-inverse-cdf-case-1}
**Case 2)** when $\xi = 0$, we get the following from @eq-gpd-cdf, like above let $y = F(x;\,\sigma,\xi, u)$

$$
\begin{aligned}
y &= 1 - \exp\!\left(-\dfrac{x-u}{\sigma}\right)\\
1 - y &= \exp\!\left(-\dfrac{x-u}{\sigma}\right)\\
ln(1-y) &= -\dfrac{x-u}{\sigma}\\
-(x-u) &= \sigma ln(1-y)\\
x &= -\sigma ln(1-y) + u\\
\implies F^{-1}_X(y) &= -\sigma ln(1-y) + u
\end{aligned}
$${#eq-gpd-inverse-cdf-case-2}

Hence, combining @eq-gpd-inverse-cdf-case-1 and @eq-gpd-inverse-cdf-case-2 our well defined $F^{-1}_X: [0,1] \rightarrow [u, x^+]$ of $X \sim \text{GPD}(u, \sigma, \xi)$ is as follows: 

$$
F^{-1}_X(y;\,\sigma,\xi, u) = 
\begin{cases}
u -\dfrac{\sigma}{\xi}(1 - (1-y)^{-\xi}) , & \xi \neq 0, \; \; \\[1.2em]
u - \sigma ln(1-y) ,  & \xi = 0\;
\end{cases}
$$ {#eq-gpd-inverse-cdf}


### Question 2 

_For this question you should display the R code you use to define and document `qgpd()` within the main text of your report._

(a) Write and document your own function `qgpd()` to calculate quantiles of a given generalised Pareto distribution. Your function should have inputs and behaviour similar to the built-in R functions such as `qnorm()` and `qunif()` and check that inputs are in the correct format. 

(b) Suppose a random variable $X$ follows an generalised Pareto distribution with threshold parameter $u=1.5$, scale parameter $\sigma = 2$ and shape parameter $\xi = -0.4$. Use your function to find quantiles $x_p$ for $p = 0.5, 0.75, 0.99$ (i.e. for each $p$ find the value for which $\Pr(X < x_p) = p$).


:::{.callout-tip}
## Set yourself up for success

Does your answer: 

- contain a valid R function definition;
- document the expected inputs, outputs and behaviours of that function;
- check the validity of inputs;
- handle any edge-cases in an appropriate way;
- return the correct quantile values? 

:::

```{r}
#' Title
#'
#' @param p  probability, should be between 0 and 1 (inclusive)
#' @param xi shape parameter, should be a real number
#' @param sigma scale parameter, should be positive
#' @param u location parameter, should be a real number
#'
#' @returns a vector/ numeric quantile (or inverse cumulative distribution) corresponding to the probability p corresponding to the generalized pareto distribution with the given parameters
#' @export
#'
#' @examples


qgpd <- function(p, xi, sigma, u) {
  # chekcing all the parameters are numeric
  if (!is.numeric(p)) stop("Argument 'p' must be numeric.")
  if (!is.numeric(xi)) stop("Argument 'xi' must be numeric.")
  if (!is.numeric(sigma)) stop("Argument 'sigma' must be numeric.")
  if (!is.numeric(u)) stop("Argument 'u' must be numeric.")
  
  # Check for valid scale parameter.
  if (any(sigma <= 0)) {
    stop("The scale parameter 'sigma' must be positive.")
  }
  

   # Add validation for the probability 'p'
  if (any(p < 0) || any(p > 1)) {
    stop("Probabilities 'p' must be between 0 and 1.")
  }
  
  # the two cases for the shape parameter `xi`.
  
  # `ifelse` will test `xi == 0` for each element and pick the appropriate formula.
  
   return (ifelse(
    xi == 0,
    # Formula for xi = 0
    u - sigma * log(1 - p),
    # Formula for xi != 0
    u - (sigma / xi) * (1 - (1 - p) ** (-xi))
    ))

}

# Calculate quantiles for X ~ GPD(u=1.5, sigma=2, xi=-0.4)
# Quantile for p = 0.5
quantile_p05 <- qgpd(p = 0.5, u = 1.5, sigma = 2, xi = -0.4)

# Quantile for p = 0.75
quantile_p75 <- qgpd(p = 0.75, u = 1.5, sigma = 2, xi = -0.4)

# Quantile for p = 0.99
quantile_p99 <- qgpd(p = 0.99, u = 1.5, sigma = 2, xi = -0.4)


cat(
  "The quantile for p = 0.50 is:", quantile_p05, "\n",
  "The quantile for p = 0.75 is:", quantile_p75, "\n",
  "The quantile for p = 0.99 is:", quantile_p99, "\n"
)

```

### Question 3

_For this question, all R code should be displayed only within the appendix, not in the main report._

The file `gpd_samples.csv` contains six sets of random variates generated from different generalised Pareto distributions. The details of the generalised Pareto distributions used are summarised in `gpd_parameters.csv`. Unfortunately some of the parameter sets were recorded incorrectly. 

Within a single figure, construct a series of quantile-quantile plots to identify which datasets are inconsistent with their stated distributions. You should both justify your conclusions and describe your level of confidence in your findings. 

::: {.callout-tip}
## Set yourself up for success 

Does your solution contain: 

- at least one quantile-quantile plot;
- six qq-plots in a single figure;
- use of loops, vectorisation, or function definitions to avoid repetitive code.
- figures with clear text, useful captions and appropriate visual mapping of data;
- a few paragraphs describing and justifying your findings and referencing the figure;

:::

<!-- YOUR ANSWER GOES HERE --> 



```{r}
#| label: fig-gpd-qq
#| echo: false
#| warning: false
#| fig-cap: "Q–Q Plots for GPD Samples: Non_sim vs. sim Parameters"
#| layout-ncol: 2
#| fig-subcap: ["Set a", "Set b", "Set c", "Set d", "Set e", "Set f"]

samples <- read.csv("gpd_samples.csv")
params <- read.csv("gpd_parameters.csv")

plots <- list()

# Get the unique set IDs to loop through
set_ids <- unique(params$id)

for (current_id in set_ids) {
  sample_data <- samples$value[samples$set_id == current_id]
  sample_data <- sort(sample_data)
  stated_params <- params[params$id == current_id, ]
  
  n <- length(sample_data)
  # create a set of evenly spaced probabilities for the theoretical distribution
  theoretical_probs <- (1:n - 0.5) / n
  
  #initialize an empty vector to store the results
  theoretical_quantiles <- numeric(n)

  # use qgpd function to find the corresponding theoretical quantiles
  # Using for loop, could use vectorisation, but this helps me be in control
  for (i in 1:n) {
    theoretical_quantiles[i] <- qgpd(
      p = theoretical_probs[i], 
      xi = stated_params$xi,
      sigma = stated_params$sigma,
      u = stated_params$u
    )
  }
  
# use qgpd function to find the corresponding theoretical quantiles for sim
  theoretical_quantiles_sim <- numeric(n)
  for (i in 1:n) {
    theoretical_quantiles_sim[i] <- qgpd(
      p = theoretical_probs[i], 
      xi = stated_params$xi_sim,
      sigma = stated_params$sig_sim,
      u = stated_params$u_sim
    )
  }
  
  df <- data.frame(
    Empirical = sample_data,
    Theoretical = theoretical_quantiles,
    Simulated = theoretical_quantiles_sim
  )
  
  p <- ggplot(df) +
    geom_point(aes(x = Theoretical, y = Empirical, color = "Non_sim Params"), alpha = 0.8) +
    geom_point(aes(x = Simulated, y = Empirical, color = "Sim Params"), alpha = 0.5) +
    geom_abline(intercept = 0, slope = 1, color = "green", size = 1) +
    labs(
      title = paste0("Q-Q Plot for Set '", current_id, "' (n=", n, ")"),
      x = "Theoretical Quantiles",
      y = "Empirical Quantiles",
      color = ""
    ) +
    theme_minimal() +
    scale_color_manual(values = c("Non_sim Params" = "blue", "Sim Params" = "red"))
  
  plots[[current_id]] <- p
}

plots[[1]]; plots[[2]]; plots[[3]]; plots[[4]]; plots[[5]]; plots[[6]]
```

In @fig-gpd-qq, six different quantile-quantile (Q-Q) plots are shown, corresponding to sets `(a)`, `(b)`, ... `(f)`. Each plot compares empirical quantiles from the data in `gpd_samples.csv` against theoretical quantiles from a Generalized Pareto Distribution (GPD). Two parameter sets are used from the file `gpd_parameters.csv` : the simulated parameters (red dots) and the stated/ non_sim parameters (blue dots).


In @fig-gpd-qq-1, the points corresponding to the sim parameter lie close to the line $y = x$, indicating good agreement between the empirical and theoretical quantiles. In contrast, the points corresponding to the non_sim/ stated parameter deviate substantially from the line. This graphical evidence allows us to conclude with a high level of confidence that the stated parameters are incorrect and were not used to generate the simulated data. (as stated in the question itself). 

On first glance, we can observe that for set `(b)` @fig-gpd-qq-2, both the non-sim and sim parameter points lie very close to the line $y = x$. As the points are all very close to the line and only deviate a little on top as well as the sample size is fairly large, we can say with high confidence that the stated parameters are likely the true parameters used to generate the simulated data.
A similar argument can be made for @fig-gpd-qq-6, which relates to the data from set `(f)`.

Like sets `(b)` and `(f)`, @fig-gpd-qq-3, shows that sim and non_sim points coincide and lie close to the line $y =x$. However, there are a few deviations, despite the small sample size ($n =20$). 

In @fig-gpd-qq-4, for `(d)` the simulated and non-simulated points lie close to each other but both deviate significantly from the line $y = x$, where the points would ideally fall. Since we are told that the simulated parameters were used to generate the data, this deviation is likely due to randomness or sampling variability. However, based on the Q–Q plots alone, we cannot confidently determine whether the simulated or non-simulated parameters were used to generate the data.

In @fig-gpd-qq-5, for set `(e)` the simulated and non-simulated points lie far away from each other and both deviate significantly from the line $y = x$. The non_sim parameters appear to be closer to the line than the sim parameters. Similar to our conclusion for set `(d)`, based on the Q–Q plots alone, we cannot confidently determine whether the simulated or non-simulated parameters were used to generate the data.



### Question 4

_For this question, all R code should be displayed only within the appendix, not in the main report._

A hydrologist is interested in understanding the river flow at a location that is historically prone to flooding. There is a river flow gauge nearby which measures river flow in units of cubic meters per second ($\text{m}^3/\text{s}$ or cumecs). Based on her knowledge of other rivers, the hydrologist proposes that for this river gauge:

 - the distribution of river flow values is constant over time 
 - for river flows exceeding 75 cumecs, it is appropriate to model these data as independent and identically distributed GPD($\sigma =29.7$, $\xi=0.62$, $u = 0$). 

Use `riverflow_2015-2024.csv` to conduct an exploratory investigation of whether these proposals are valid for the dataset provided. Summarise your findings in 250-350 words, supporting these with a collection of 4 visualisations/figures. 


::: {.callout-tip}
## Set yourself up for success 

Does your answer contain: 

- 400-500 words of text clearly describing your choice of visualisations, their interpretation and your conclusions about the validity of each assumption,
- A series of 4 visualisations / figures,
- A varied and appropriate choice of figures to investigate each of the hydrologist's proposals,
- Figures with clear text, useful captions and appropriate visual mapping of data;
- At least one reference to each visualisation within the main text.
:::


<!-- YOUR INVESTIGATION GOES HERE --> 

**Proposal 1: ** To investigate Proposal 1 "the distribution of river flow values is constant over time", we will first create a time series plot to see the riverflow.

```{r}
#| echo: false

# Load the river flow data from the CSV file
river_data <- read.csv("riverflow_2015_2024.csv")

# Convert the 'date' column from text to R's Date format
river_data$date <- as.Date(river_data$date)

```

```{r}
#| label: fig-riverflow-ts
#| echo: false
#| warning: false
#| fig-cap: "River flow from 2015 to 2024"

# --- Time Series Plot ---
plot(
  river_data$date,
  river_data$flow,
  type = 'l', # 'l' for line plot
  col = "dodgerblue",
  main = "River Flow (2015-2024)",
  xlab = "Year",
  ylab = expression("Flow (m"^3*"/s)") 
)
grid()
```

However, in the csv file, we can see there are some extreme data (given from the column `is_extreme`), so first checking that the number of extreme values are almost equal per year so that we are not adding bias to our investigation.

```{r}
#| label: fig-yearly-extremes
#| echo: false
#| warning: false
#| fig-cap: "Number of extreme flow events per year"

#Filter for extreme events
extreme_data <- river_data[river_data$is_extreme == "True", ]

# Extract the year from the date
extreme_data$year <- format(extreme_data$date, "%Y")

# c. Count the number of extreme events per year
yearly_counts <- table(extreme_data$year)

# d. Create the bar plot
barplot(
  yearly_counts,
  main = "Annual Count of Extreme Flow Events",
  xlab = "Year",
  ylab = "Number of Days with Extreme Flow",
  col = "tomato"
)
grid(nx = NA, ny = NULL)
```

As we can see from @fig-yearly-extremes that the number of extremes is almost similar so we can only consider non-extreme data.


```{r}
#| label: fig-riverflow-non-extreme
#| echo: false
#| warning: false
#| fig-cap: "Time series of non-extreme daily river flow along with baseline mean"

# Create a subset of the data containing only the non-extreme flows.
non_extreme_data <- river_data[river_data$is_extreme == "False", ]

# --- Time Series Plot of Non-Extreme Values ---
plot(
  non_extreme_data$date,
  non_extreme_data$flow,
  type = 'l', # 'l' for line plot
  col = "seagreen",
  main = "Non-Extreme River Flow (2015-2024)",
  xlab = "Year",
  ylab = expression("Flow (m"^3*"/s)")
)
lines(
  non_extreme_data$date,
  non_extreme_data$baseline_mean,
  col = "darkred",
  lwd = 2,
  lty = 2
)
grid()
legend(
  "topright",
  legend = c("River Flow", "Baseline Mean"),
  col = c("seagreen", "darkred"),
  lwd = c(1, 2),
  lty = c(1, 2),
  bty = "n"
)
```

Figure @fig-riverflow-non-extreme clearly reveals a strong seasonal pattern. The data exhibits cyclical peaks and troughs that recur annually, suggesting that river flow is influenced by seasonal weather patterns. This directly contradicts the proposal that the distribution of river flow remains constant over time. The dotted red line represents the provided `baseline_mean`, which also shows a distinct seasonal trend and a slight upward drift over the years, further contradicting the hydrologist’s proposal. In conclusion, the river flow is not constant over time, it exhibits a clear seasonal trend, and the mean appears to be gradually increasing. This indicates that both the variability and the average level of river flow change over time.




We will also look at boxplots by months to further our reasoning. 

```{r}
#| label: fig-monthly-boxplot
#| echo: false
#| warning: false
#| fig-cap: "Distribution of daily river flow by month (2015-2024)"

non_extreme_data$month <- factor(format(non_extreme_data$date, "%b"), levels = month.abb)

boxplot(
  flow ~ month,
  data = non_extreme_data,
  col = "skyblue",
  main = "Monthly River Flow Distribution",
  xlab = "Month",
  ylab = expression("Flow (m"^3*"/s)")
)
grid(nx = NA, ny = NULL)
```



**Proposal 2: **
Considering the riverflow values of those only above 75 and then subtracting $75$ from it because our location parameter is given to be 0, which usually is defined by the minimum value in the distribution. and so we are trying to model the excess above 75.
```{r}
#| echo: false
threshold <- 75
proposal_2_data <- river_data[river_data$flow > threshold, ]
```



```{r}
#| label: fig-gpd-qqplot-q4
#| echo: false
#| warning: false
#| fig-cap: "Q-Q plot of river flow vs. theoretical GPD"

# Get the empirical quantiles by sorting the  data
empirical_quantiles <- sort(proposal_2_data$flow - 75) 

# Define the hydrologist's proposed parameters
gpd_params <- list(sigma = 29.7, xi = 0.62, u = 0)

# c. Generate the theoretical quantiles
n <- length(empirical_quantiles)
theoretical_probs <- (1:n - 0.5) / n
# Initialize an empty vector to store the results
theoretical_quantiles <- numeric(n) 
for (i in 1:n) {
  theoretical_quantiles[i] <- qgpd(
    p = theoretical_probs[i],
    xi = gpd_params$xi,
    sigma = gpd_params$sigma,
    u = gpd_params$u
  )
}

qq_data <- data.frame(
  Theoretical = theoretical_quantiles,
  Empirical = empirical_quantiles
)

ggplot(qq_data, aes(x = Theoretical, y = Empirical)) +
  geom_point(color = "darkred") +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = "dashed", linewidth = 1) +
  ggtitle(expression(paste("Q-Q Plot for River Flow in excess of 75 cm"^3))) +
  xlab("Theoretical GPD Quantiles") +
  ylab("Empirical (Sample) Quantiles") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid = element_line(color = "grey")
  )

```
```{r}
#| label: fig-acf-q4
#| echo: false
#| warning: false
#| fig-cap: "Autocorrelation of Extreme Flow"
acf(
  proposal_2_data$flow,
  lag.max = 30
)

```


::: {.callout-tip}
## Set yourself up for success 

- Does your document render without any formatting issues? 
:::

_End of Assessment._


# Code Appendix {#sec-code-appendix}

```{r ref.label=knitr::all_labels()}
#| echo: true
#| eval: false
#| code-fold: true
```






